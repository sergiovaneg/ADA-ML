{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sergiovaneg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure\n",
    "\n",
    "import scipy.io\n",
    "from statsmodels.tsa.seasonal import STL, DecomposeResult\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import wordcloud\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"./report/figures/\"):\n",
    "  os.makedirs(\"./report/figures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water dataset\n",
    "## Import and visualize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_dataset = scipy.io.loadmat(\"./WaterQualityData.mat\")\n",
    "N = water_dataset[\"Ydata\"].shape[0]\n",
    "seasonal = 21\n",
    "\n",
    "x_data = pd.DataFrame(water_dataset[\"Xdata\"],\n",
    "                   index=pd.date_range(start=dt.datetime(2016, 1, 28, 8),\n",
    "                                       periods=N, freq=\"D\"))\n",
    "y_data = pd.DataFrame(water_dataset[\"Ydata\"],\n",
    "                   index=pd.date_range(start=dt.datetime(2016, 1, 28, 8),\n",
    "                                       periods=N, freq=\"D\"))\n",
    "\n",
    "def stl_custom_plot(data:pd.Series, seasonal:int, trend:int,\n",
    "                    suptitle:str, save_path:str,\n",
    "                    figsize:tuple[int,int]=(10,6), period = None)-> matplotlib.figure.Figure:\n",
    "  stl = STL(data, seasonal=seasonal, trend=trend, robust=True, period=period).fit()\n",
    "\n",
    "  fig = plt.figure(figsize=figsize)\n",
    "  axes = fig.subplots(4,1, sharex=True)\n",
    "  axes[0].plot(data.index, stl.observed); axes[0].set_ylabel(\"Original\")\n",
    "  axes[1].plot(data.index, stl.trend); axes[1].set_ylabel(\"Trend\")\n",
    "  axes[2].plot(data.index, stl.seasonal); axes[2].set_ylabel(\"Seasonality\")\n",
    "  axes[3].plot(data.index, stl.resid); axes[3].set_ylabel(\"Residual\")\n",
    "  for idx in range(4):\n",
    "    axes[idx].autoscale(enable=True, axis=\"x\", tight=True)\n",
    "  fig.suptitle(suptitle)\n",
    "  fig.savefig(fname=save_path)\n",
    "\n",
    "  return fig;\n",
    "\n",
    "fig = stl_custom_plot(x_data.iloc[:,0].squeeze(), seasonal, None,\n",
    "                      \"Input automatic STL decomposition\",\n",
    "                      \"./report/figures/x_decomp.eps\")\n",
    "plt.close(fig)\n",
    "\n",
    "fig = stl_custom_plot(y_data.squeeze(), seasonal, None,\n",
    "                      \"Output automatic STL decomposition\",\n",
    "                      \"./report/figures/y_decomp.eps\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = stl_custom_plot(y_data.squeeze(), seasonal, None,\n",
    "                      f\"Input STL decomposition\\nPeriod: weekly\",\n",
    "                      \"./report/figures/weekly_decomp.eps\", period=7)\n",
    "plt.close(fig)\n",
    "\n",
    "fig = stl_custom_plot(y_data.squeeze(), seasonal, None,\n",
    "                      f\"Output STL decomposition\\nPeriod: monthly\",\n",
    "                      \"./report/figures/monthly_decomp.eps\", period=30)\n",
    "plt.close(fig)\n",
    "\n",
    "fig = stl_custom_plot(y_data.squeeze(), seasonal, None,\n",
    "                      f\"Output STL decomposition\\nPeriod: quarterly\",\n",
    "                      \"./report/figures/quarterly_decomp.eps\", period=90)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output-variable K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "y_clusters = KMeans(n_clusters=n_clusters, n_init=100).fit_predict(y_data)\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "for cluster in range(n_clusters):\n",
    "  cluster_idxs = (y_clusters == cluster)\n",
    "  plt.scatter(y_data.index[cluster_idxs], y_data.iloc[cluster_idxs,0])\n",
    "fig.savefig(\"./report/figures/clustered_by_output.eps\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-variate K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "x_clusters = KMeans(n_clusters=n_clusters, n_init=100).fit_predict(x_data)\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "for cluster in range(n_clusters):\n",
    "  cluster_idxs = (x_clusters == cluster)\n",
    "  plt.scatter(y_data.index[cluster_idxs], y_data.iloc[cluster_idxs,0])\n",
    "fig.savefig(\"./report/figures/clustered_by_input.eps\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Text Data\n",
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7ff4cbeac910>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dagon_text = open(\"./dagon.txt\", \"r\").read()\n",
    "ctulhu_mask = 255 - np.array(Image.open(\"./cthulhu.png\").convert(\"L\"))[30:1150, 20:1200]\n",
    "  \n",
    "stopwords = set.union(set(stopwords.words(\"english\")),\n",
    "                      set(wordcloud.STOPWORDS))\n",
    "\n",
    "wc = wordcloud.WordCloud(background_color=\"black\", max_words=100,\n",
    "                         mask=ctulhu_mask, stopwords=stopwords,\n",
    "                         contour_width=1, contour_color=\"green\",\n",
    "                         mode=\"RGB\")\n",
    "\n",
    "wc.generate(dagon_text)\n",
    "wc.to_file(\"./report/figures/wordcloud.png\")\n",
    "\n",
    "dagon_text_tokenized = \\\n",
    "  word_tokenize(re.sub(r\"[^\\w\\s]\", \"\", dagon_text.lower()))\n",
    "dagon_text_processed = \" \".join(dagon_text_tokenized)\n",
    "\n",
    "bigram = {}\n",
    "for (a,b) in zip(dagon_text_tokenized[:-1], dagon_text_tokenized[1:]):\n",
    "  if a in stopwords and b in stopwords:\n",
    "    continue\n",
    "  couple = \" \".join([a,b])\n",
    "  if couple not in bigram.keys():\n",
    "    bigram[couple] = 1\n",
    "  else:\n",
    "    bigram[couple] = bigram[couple] + 1\n",
    "\n",
    "wc.generate_from_frequencies(bigram)\n",
    "wc.to_file(\"./report/figures/wordcloud_2N.png\")\n",
    "\n",
    "trigram = {}\n",
    "for (a,b,c) in zip(dagon_text_tokenized[:-2], dagon_text_tokenized[1:-1], dagon_text_tokenized[2:]):\n",
    "  if a in stopwords or b in stopwords or c in stopwords:\n",
    "    continue\n",
    "  triple = \" \".join([a,b,c])\n",
    "  if triple not in bigram.keys():\n",
    "    trigram[triple] = 1\n",
    "  else:\n",
    "    trigram[triple] = trigram[triple] + 1\n",
    "\n",
    "wc.generate_from_frequencies(trigram)\n",
    "wc.to_file(\"./report/figures/wordcloud_3N.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
