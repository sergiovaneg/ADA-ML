{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"./models/\"):\n",
    "  os.makedirs(\"./models/\")\n",
    "if not os.path.exists(\"./report/figures/\"):\n",
    "  os.makedirs(\"./report/figures/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "solar_energy_df = pd.read_csv(\"../ML_week3/solarenergy.csv\",\n",
    "                              delimiter=\",\",\n",
    "                              index_col=0,\n",
    "                              date_format=\"%d/%m/%Y %H:%M\",\n",
    "                              parse_dates=True).sort_index()\n",
    "\n",
    "\"\"\"\n",
    "solar_energy_df[\"Datetime\"] = pd.to_datetime(solar_energy_df[\"Datetime\"],\n",
    "                                             format=\"%d/%m/%Y %H:%M\")\n",
    "solar_energy_df = solar_energy_df.set_index(\"Datetime\").sort_index()\n",
    "\"\"\"\n",
    "\n",
    "solar_energy_df = solar_energy_df.dropna()\n",
    "solar_energy_df = solar_energy_df.resample(\"1H\").interpolate(\"linear\")\n",
    "solar_energy_df = \\\n",
    "  (solar_energy_df - solar_energy_df.mean()) / solar_energy_df.std()\n",
    "\n",
    "training_ratio = 0.7\n",
    "\n",
    "training_limit = \\\n",
    "  solar_energy_df.index[\n",
    "      int(training_ratio*solar_energy_df.shape[0])\n",
    "    ]\n",
    "\n",
    "y_train_df = solar_energy_df.loc[:training_limit-pd.Timedelta(hours=1),\n",
    "                                  \"solar_mw\"]\n",
    "y_test_df = solar_energy_df.loc[training_limit:, \"solar_mw\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 16:15:05.914865: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-23 16:15:06.021106: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-23 16:15:06.021183: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-23 16:15:06.021203: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-23 16:15:06.071570: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-23 16:15:09.117503: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 16:15:09.195400: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 16:15:09.195647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 16:15:09.197542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 16:15:09.197726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 16:15:09.197845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 16:15:09.244693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 16:15:09.245164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 16:15:09.245320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 16:15:09.245423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2288 MB memory:  -> device: 0, name: NVIDIA RTX A500 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from pydantic import NonNegativeInt, PositiveInt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "n_feats = 1\n",
    "p=10\n",
    "q=48\n",
    "\n",
    "def tensor_memory_reshaper(in_np:np.ndarray, out_np:Optional[np.ndarray],\n",
    "                           memory:NonNegativeInt,\n",
    "                           n_feats_internal:PositiveInt = n_feats):\n",
    "  in_np = in_np.reshape((-1,1,n_feats_internal))\n",
    "  for _ in range(memory):\n",
    "    next_np = in_np[1:,-1,:].reshape(((-1,1,n_feats_internal)))\n",
    "    in_np = np.concatenate((in_np[:-1,:,:], next_np), axis=1)\n",
    "\n",
    "  if out_np is not None:\n",
    "    return (tf.convert_to_tensor(in_np),\n",
    "            tf.convert_to_tensor(out_np[memory:]))\n",
    "  else:\n",
    "    return (tf.convert_to_tensor(in_np), None)\n",
    "  \n",
    "x_train_np = np.pad(\n",
    "    y_train_df[:-1].to_numpy().reshape((-1,1)), ((q+1,0),(0,0)), mode=\"edge\"\n",
    "  )\n",
    "y_train_np = np.pad(y_train_df.to_numpy(), ((q,0),), mode=\"edge\")\n",
    "\n",
    "x_test_np = pd.concat(\n",
    "    (y_train_df.iloc[-(q+1):], y_test_df[:-1])\n",
    "  ).to_numpy().reshape((-1,1))\n",
    "y_test_np = pd.concat((y_train_df.iloc[-q:], y_test_df)).to_numpy()\n",
    "\n",
    "x_train_tensor,y_train_tensor = \\\n",
    "  tensor_memory_reshaper(x_train_np, y_train_np, q)\n",
    "_,y_test_tensor = \\\n",
    "  tensor_memory_reshaper(x_test_np, y_test_np, q)\n",
    "\n",
    "class StateResetCallback(keras.callbacks.Callback):\n",
    "  def on_epoch_begin(self, epoch, logs=None):\n",
    "    self.model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 16:15:10.622494: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-23 16:15:11.279535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8800\n",
      "2023-11-23 16:15:11.465451: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-23 16:15:11.721608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1bb27e4b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-23 16:15:11.721649: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A500 Laptop GPU, Compute Capability 8.6\n",
      "2023-11-23 16:15:11.730164: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-23 16:15:11.823594: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: {'serial': 'model_20231123161509', 'head_size': 2, 'num_heads': 5, 'ff_dim': 10, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9521070786350811, 'MAE': 2.4080189779009054}\n",
      "Model: {'serial': 'model_20231123161600', 'head_size': 2, 'num_heads': 5, 'ff_dim': 10, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9430197308543782, 'MAE': 2.3594687297548482}\n",
      "Model: {'serial': 'model_20231123161643', 'head_size': 2, 'num_heads': 5, 'ff_dim': 10, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.9594363457021841, 'MAE': 2.3880907907690236}\n",
      "Model: {'serial': 'model_20231123161719', 'head_size': 2, 'num_heads': 5, 'ff_dim': 20, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 1.063124590954646, 'MAE': 2.642023058196468}\n",
      "Model: {'serial': 'model_20231123161805', 'head_size': 2, 'num_heads': 5, 'ff_dim': 20, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 192164.8558499995, 'MAE': 1145306.4930827303}\n",
      "Model: {'serial': 'model_20231123161852', 'head_size': 2, 'num_heads': 5, 'ff_dim': 20, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 1.0268371068906186, 'MAE': 2.6974034025873372}\n",
      "Model: {'serial': 'model_20231123161945', 'head_size': 2, 'num_heads': 5, 'ff_dim': 50, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9505549503690575, 'MAE': 2.3521751850451658}\n",
      "Model: {'serial': 'model_20231123162025', 'head_size': 2, 'num_heads': 5, 'ff_dim': 50, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 1.0192796422612478, 'MAE': 2.708425076266689}\n",
      "Model: {'serial': 'model_20231123162114', 'head_size': 2, 'num_heads': 5, 'ff_dim': 50, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 10533357836.272825, 'MAE': 82556002304.24309}\n",
      "Model: {'serial': 'model_20231123162157', 'head_size': 2, 'num_heads': 10, 'ff_dim': 10, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 1.8537694677638472, 'MAE': 3.7511854484285543}\n",
      "Model: {'serial': 'model_20231123162248', 'head_size': 2, 'num_heads': 10, 'ff_dim': 10, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9791360509240093, 'MAE': 2.38670154060976}\n",
      "Model: {'serial': 'model_20231123162330', 'head_size': 2, 'num_heads': 10, 'ff_dim': 10, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.9067067290265132, 'MAE': 2.380997525116367}\n",
      "Model: {'serial': 'model_20231123162411', 'head_size': 2, 'num_heads': 10, 'ff_dim': 20, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 1.024879145411562, 'MAE': 2.609375150462551}\n",
      "Model: {'serial': 'model_20231123162455', 'head_size': 2, 'num_heads': 10, 'ff_dim': 20, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9314041344305214, 'MAE': 2.3817228763903806}\n",
      "Model: {'serial': 'model_20231123162542', 'head_size': 2, 'num_heads': 10, 'ff_dim': 20, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.9989386389136223, 'MAE': 2.5340944245065877}\n",
      "Model: {'serial': 'model_20231123162629', 'head_size': 2, 'num_heads': 10, 'ff_dim': 50, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.955537015703056, 'MAE': 2.5802541091646383}\n",
      "Model: {'serial': 'model_20231123162725', 'head_size': 2, 'num_heads': 10, 'ff_dim': 50, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 1.012716061994322, 'MAE': 2.509222928550283}\n",
      "Model: {'serial': 'model_20231123162807', 'head_size': 2, 'num_heads': 10, 'ff_dim': 50, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.9609991293155707, 'MAE': 2.406908245345516}\n",
      "Model: {'serial': 'model_20231123162858', 'head_size': 2, 'num_heads': 20, 'ff_dim': 10, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 1.3675643172942036, 'MAE': 2.8117198768194056}\n",
      "Model: {'serial': 'model_20231123162942', 'head_size': 2, 'num_heads': 20, 'ff_dim': 10, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9320854545319248, 'MAE': 2.25283721234457}\n",
      "Model: {'serial': 'model_20231123163019', 'head_size': 2, 'num_heads': 20, 'ff_dim': 10, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.910187434589573, 'MAE': 2.4629476382936666}\n",
      "Model: {'serial': 'model_20231123163105', 'head_size': 2, 'num_heads': 20, 'ff_dim': 20, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 1.196158342489993, 'MAE': 2.9035978033746908}\n",
      "Model: {'serial': 'model_20231123163136', 'head_size': 2, 'num_heads': 20, 'ff_dim': 20, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 1.2011773328655946, 'MAE': 2.8975485279764364}\n",
      "Model: {'serial': 'model_20231123163215', 'head_size': 2, 'num_heads': 20, 'ff_dim': 20, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 7.16836013634594, 'MAE': 28.593986594900045}\n",
      "Model: {'serial': 'model_20231123163315', 'head_size': 2, 'num_heads': 20, 'ff_dim': 50, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 1.0244868407439875, 'MAE': 2.5441185548509786}\n",
      "Model: {'serial': 'model_20231123163354', 'head_size': 2, 'num_heads': 20, 'ff_dim': 50, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9576388844753404, 'MAE': 2.0711728106596827}\n",
      "Model: {'serial': 'model_20231123163423', 'head_size': 2, 'num_heads': 20, 'ff_dim': 50, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.9148146378446008, 'MAE': 2.337441788574619}\n",
      "Model: {'serial': 'model_20231123163502', 'head_size': 5, 'num_heads': 5, 'ff_dim': 10, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9765923773844256, 'MAE': 2.3841623454894254}\n",
      "Model: {'serial': 'model_20231123163547', 'head_size': 5, 'num_heads': 5, 'ff_dim': 10, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9741420706514732, 'MAE': 2.499709890743656}\n",
      "Model: {'serial': 'model_20231123163622', 'head_size': 5, 'num_heads': 5, 'ff_dim': 10, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.9650394545142155, 'MAE': 2.3580616950596998}\n",
      "Model: {'serial': 'model_20231123163657', 'head_size': 5, 'num_heads': 5, 'ff_dim': 20, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 1.0436158938731122, 'MAE': 2.5833427026476095}\n",
      "Model: {'serial': 'model_20231123163734', 'head_size': 5, 'num_heads': 5, 'ff_dim': 20, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9909453269625405, 'MAE': 2.407962070366306}\n",
      "Model: {'serial': 'model_20231123163815', 'head_size': 5, 'num_heads': 5, 'ff_dim': 20, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.92079366514591, 'MAE': 2.2579259753389453}\n",
      "Model: {'serial': 'model_20231123163900', 'head_size': 5, 'num_heads': 5, 'ff_dim': 50, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 1.0035692851245424, 'MAE': 2.4865880027021596}\n",
      "Model: {'serial': 'model_20231123163957', 'head_size': 5, 'num_heads': 5, 'ff_dim': 50, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9664243872061586, 'MAE': 2.40800817455904}\n",
      "Model: {'serial': 'model_20231123164052', 'head_size': 5, 'num_heads': 5, 'ff_dim': 50, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.8858161052917711, 'MAE': 2.205087873355875}\n",
      "Model: {'serial': 'model_20231123164133', 'head_size': 5, 'num_heads': 10, 'ff_dim': 10, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9187872220844221, 'MAE': 2.330301237812204}\n",
      "Model: {'serial': 'model_20231123164207', 'head_size': 5, 'num_heads': 10, 'ff_dim': 10, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.8628290797222841, 'MAE': 2.1666957169933414}\n",
      "Model: {'serial': 'model_20231123164236', 'head_size': 5, 'num_heads': 10, 'ff_dim': 10, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.9540797268858101, 'MAE': 2.4756042673792074}\n",
      "Model: {'serial': 'model_20231123164318', 'head_size': 5, 'num_heads': 10, 'ff_dim': 20, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9808094481182771, 'MAE': 2.4523985996450612}\n",
      "Model: {'serial': 'model_20231123164404', 'head_size': 5, 'num_heads': 10, 'ff_dim': 20, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 1.029851160910552, 'MAE': 2.610589863320751}\n",
      "Model: {'serial': 'model_20231123164446', 'head_size': 5, 'num_heads': 10, 'ff_dim': 20, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.8408493767233888, 'MAE': 2.0884709760708904}\n",
      "Model: {'serial': 'model_20231123164527', 'head_size': 5, 'num_heads': 10, 'ff_dim': 50, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9109625900325771, 'MAE': 2.3443871229495237}\n",
      "Model: {'serial': 'model_20231123164559', 'head_size': 5, 'num_heads': 10, 'ff_dim': 50, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9097551268807017, 'MAE': 1.998255829529295}\n",
      "Model: {'serial': 'model_20231123164631', 'head_size': 5, 'num_heads': 10, 'ff_dim': 50, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 21476.78264826296, 'MAE': 123077.0087077303}\n",
      "Model: {'serial': 'model_20231123164701', 'head_size': 5, 'num_heads': 20, 'ff_dim': 10, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9900081477719588, 'MAE': 2.4740760191883275}\n",
      "Model: {'serial': 'model_20231123164745', 'head_size': 5, 'num_heads': 20, 'ff_dim': 10, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 1.1537282647312495, 'MAE': 2.8686836078371236}\n",
      "Model: {'serial': 'model_20231123164814', 'head_size': 5, 'num_heads': 20, 'ff_dim': 10, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.9068510229624537, 'MAE': 2.334516817292137}\n",
      "Model: {'serial': 'model_20231123164846', 'head_size': 5, 'num_heads': 20, 'ff_dim': 20, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9739034538791634, 'MAE': 2.4214317366089055}\n",
      "Model: {'serial': 'model_20231123164923', 'head_size': 5, 'num_heads': 20, 'ff_dim': 20, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9257138250424297, 'MAE': 2.266848184687955}\n",
      "Model: {'serial': 'model_20231123164959', 'head_size': 5, 'num_heads': 20, 'ff_dim': 20, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.967517871965305, 'MAE': 2.3927107616867254}\n",
      "Model: {'serial': 'model_20231123165041', 'head_size': 5, 'num_heads': 20, 'ff_dim': 50, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.893820236168566, 'MAE': 2.2231001436872577}\n",
      "Model: {'serial': 'model_20231123165132', 'head_size': 5, 'num_heads': 20, 'ff_dim': 50, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9135694457917679, 'MAE': 2.2166369720901677}\n",
      "Model: {'serial': 'model_20231123165213', 'head_size': 5, 'num_heads': 20, 'ff_dim': 50, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.9665619562553298, 'MAE': 2.420171709319515}\n",
      "Model: {'serial': 'model_20231123165257', 'head_size': 10, 'num_heads': 5, 'ff_dim': 10, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9760634203588988, 'MAE': 2.3209678470696637}\n",
      "Model: {'serial': 'model_20231123165327', 'head_size': 10, 'num_heads': 5, 'ff_dim': 10, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 29.72128037337548, 'MAE': 111.21251174641631}\n",
      "Model: {'serial': 'model_20231123165412', 'head_size': 10, 'num_heads': 5, 'ff_dim': 10, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 1.0066353212737569, 'MAE': 2.4986493602003286}\n",
      "Model: {'serial': 'model_20231123165503', 'head_size': 10, 'num_heads': 5, 'ff_dim': 20, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9887105815646063, 'MAE': 2.480806381961269}\n",
      "Model: {'serial': 'model_20231123165543', 'head_size': 10, 'num_heads': 5, 'ff_dim': 20, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9300902615056812, 'MAE': 2.315852729191942}\n",
      "Model: {'serial': 'model_20231123165619', 'head_size': 10, 'num_heads': 5, 'ff_dim': 20, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.9096570352844783, 'MAE': 2.1068601936264133}\n",
      "Model: {'serial': 'model_20231123165652', 'head_size': 10, 'num_heads': 5, 'ff_dim': 50, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.914967418160239, 'MAE': 2.2600108958388994}\n",
      "Model: {'serial': 'model_20231123165729', 'head_size': 10, 'num_heads': 5, 'ff_dim': 50, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9295709340632535, 'MAE': 2.296629759685526}\n",
      "Model: {'serial': 'model_20231123165818', 'head_size': 10, 'num_heads': 5, 'ff_dim': 50, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.9066155265903882, 'MAE': 2.334771418532295}\n",
      "Model: {'serial': 'model_20231123165900', 'head_size': 10, 'num_heads': 10, 'ff_dim': 10, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9944476731745477, 'MAE': 2.4788397714103887}\n",
      "Model: {'serial': 'model_20231123165944', 'head_size': 10, 'num_heads': 10, 'ff_dim': 10, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 1.0518266012394653, 'MAE': 2.5841050460542867}\n",
      "Model: {'serial': 'model_20231123170020', 'head_size': 10, 'num_heads': 10, 'ff_dim': 10, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 1.1396563738169363, 'MAE': 2.6648115530218313}\n",
      "Model: {'serial': 'model_20231123170119', 'head_size': 10, 'num_heads': 10, 'ff_dim': 20, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9407021043382983, 'MAE': 2.202318640014095}\n",
      "Model: {'serial': 'model_20231123170204', 'head_size': 10, 'num_heads': 10, 'ff_dim': 20, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 1.6110596070004815, 'MAE': 3.796001655154977}\n",
      "Model: {'serial': 'model_20231123170237', 'head_size': 10, 'num_heads': 10, 'ff_dim': 20, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.8953011626876697, 'MAE': 2.4043802335466573}\n",
      "Model: {'serial': 'model_20231123170325', 'head_size': 10, 'num_heads': 10, 'ff_dim': 50, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 0.9014704968229802, 'MAE': 2.2779496028627584}\n",
      "Model: {'serial': 'model_20231123170401', 'head_size': 10, 'num_heads': 10, 'ff_dim': 50, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.933187439667723, 'MAE': 2.3948646649326513}\n",
      "Model: {'serial': 'model_20231123170441', 'head_size': 10, 'num_heads': 10, 'ff_dim': 50, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.8983165537840718, 'MAE': 2.38856592174427}\n",
      "Model: {'serial': 'model_20231123170535', 'head_size': 10, 'num_heads': 20, 'ff_dim': 10, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 7.146378158269749, 'MAE': 27.73413881566454}\n",
      "Model: {'serial': 'model_20231123170602', 'head_size': 10, 'num_heads': 20, 'ff_dim': 10, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 1.005839470702188, 'MAE': 2.5026015653814504}\n",
      "Model: {'serial': 'model_20231123170646', 'head_size': 10, 'num_heads': 20, 'ff_dim': 10, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 16545543.680274157, 'MAE': 118919920.24308273}\n",
      "Model: {'serial': 'model_20231123170731', 'head_size': 10, 'num_heads': 20, 'ff_dim': 20, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 1.0655795802487718, 'MAE': 2.619431824942989}\n",
      "Model: {'serial': 'model_20231123170803', 'head_size': 10, 'num_heads': 20, 'ff_dim': 20, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 1.4740413915180326, 'MAE': 3.1203258437229926}\n",
      "Model: {'serial': 'model_20231123170834', 'head_size': 10, 'num_heads': 20, 'ff_dim': 20, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.902024291293892, 'MAE': 2.157248798163796}\n",
      "Model: {'serial': 'model_20231123170914', 'head_size': 10, 'num_heads': 20, 'ff_dim': 50, 'mlp_units': 32, 'seq_memory': 48, 'RMSE': 1.0080212417242504, 'MAE': 2.5687465384210775}\n",
      "Model: {'serial': 'model_20231123170948', 'head_size': 10, 'num_heads': 20, 'ff_dim': 50, 'mlp_units': 64, 'seq_memory': 48, 'RMSE': 0.9904497179351894, 'MAE': 2.484250874778194}\n",
      "Model: {'serial': 'model_20231123171041', 'head_size': 10, 'num_heads': 20, 'ff_dim': 50, 'mlp_units': 128, 'seq_memory': 48, 'RMSE': 0.950272389575884, 'MAE': 2.323736389687223}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import transformer_SV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_dict = {}\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10,\n",
    "                                  restore_best_weights=True),\n",
    "    StateResetCallback()\n",
    "  ]\n",
    "\n",
    "date_format = \"%Y%m%d%H%M%S\"\n",
    "\n",
    "try:\n",
    "  for head_size in [2,5,10]:\n",
    "    for num_heads in [5,10,20]:\n",
    "      for ff_dim in [10,20,50]:\n",
    "        for mlp_units in [32,64,128]:\n",
    "          serial = \"model_\" + datetime.now().strftime(date_format)\n",
    "          \n",
    "          transformer_model = transformer_SV.build_model(\n",
    "              input_shape=x_train_tensor.shape[1:],\n",
    "              head_size=head_size,\n",
    "              num_heads=num_heads,\n",
    "              ff_dim=ff_dim,\n",
    "              num_transformer_blocks=1,\n",
    "              mlp_units=[mlp_units],\n",
    "              mlp_dropout=0.5,\n",
    "              dropout=0.5\n",
    "            )\n",
    "\n",
    "          transformer_model.compile(\n",
    "              loss=\"mse\",\n",
    "              optimizer=\"Adam\"\n",
    "            )\n",
    "\n",
    "          transformer_model.fit(\n",
    "              x=x_train_tensor,\n",
    "              y=y_train_tensor,\n",
    "              validation_split=0.2,\n",
    "              epochs=200,\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks,\n",
    "              verbose=0\n",
    "            )\n",
    "          transformer_model.save(f\"./models/{serial}.keras\")\n",
    "    \n",
    "          transformer_fit = transformer_model.predict(x=x_train_tensor,\n",
    "                                                      verbose=0).flatten()\n",
    "\n",
    "          transformer_prediction = np.zeros(y_test_tensor.shape)\n",
    "          buffer = y_train_np[-(q+1):].copy()\n",
    "          for idx in range(len(y_test_tensor)):\n",
    "            current_input,_ = tensor_memory_reshaper(buffer, None, q, 1)\n",
    "            transformer_prediction[idx] = \\\n",
    "              transformer_model.predict(current_input, batch_size=1,\n",
    "                                        verbose=0).flatten()[-1]\n",
    "\n",
    "            buffer[:-1] = buffer[1:]\n",
    "            buffer[-1] = transformer_prediction[idx]\n",
    "\n",
    "          transformer_rmse = np.sqrt(\n",
    "              np.mean((transformer_prediction-y_test_tensor)**2)\n",
    "            )\n",
    "          transforme_mae = np.abs(\n",
    "              transformer_prediction-y_test_tensor\n",
    "            ).max()\n",
    "\n",
    "          model_dict[serial] = {\n",
    "            \"serial\": serial,\n",
    "            \"head_size\": head_size,\n",
    "            \"num_heads\": num_heads,\n",
    "            \"ff_dim\": ff_dim,\n",
    "            \"mlp_units\": mlp_units,\n",
    "            \"seq_memory\": q,\n",
    "            \"RMSE\": transformer_rmse,\n",
    "            \"MAE\": transforme_mae\n",
    "          }\n",
    "          print(f\"Model: {model_dict[serial]}\")\n",
    "\n",
    "          plt.figure(figsize=(8,5))\n",
    "          plt.plot(solar_energy_df[\"solar_mw\"],\n",
    "                  label=\"Measured\")\n",
    "          plt.plot(y_train_df.index, transformer_fit, label=\"Fitted\")\n",
    "          plt.plot(y_test_df.index, transformer_prediction, label=\"Estimated\")\n",
    "          plt.autoscale(True, \"x\", tight=True)\n",
    "          plt.title(f\"Classic Transformer - {serial}\")\n",
    "          plt.legend()\n",
    "          plt.savefig(f\"./report/figures/{serial}_fit.svg\")\n",
    "          plt.close(\"all\")\n",
    "finally:\n",
    "  model_df = pd.DataFrame.from_dict(list(model_dict.values()))\n",
    "  model_df.to_excel(f\"./results_{datetime.now().strftime(date_format)}.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADAML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
