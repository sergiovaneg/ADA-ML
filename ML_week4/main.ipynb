{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"./models/\"):\n",
    "  os.makedirs(\"./models/\")\n",
    "if not os.path.exists(\"./report/figures/\"):\n",
    "  os.makedirs(\"./report/figures/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "solar_energy_df = pd.read_csv(\"../ML_week3/solarenergy.csv\",\n",
    "                              delimiter=\",\",\n",
    "                              index_col=0,\n",
    "                              date_format=\"%d/%m/%Y %H:%M\",\n",
    "                              parse_dates=True).sort_index()\n",
    "\n",
    "\"\"\"\n",
    "solar_energy_df[\"Datetime\"] = pd.to_datetime(solar_energy_df[\"Datetime\"],\n",
    "                                             format=\"%d/%m/%Y %H:%M\")\n",
    "solar_energy_df = solar_energy_df.set_index(\"Datetime\").sort_index()\n",
    "\"\"\"\n",
    "\n",
    "solar_energy_df = solar_energy_df.dropna()\n",
    "solar_energy_df = solar_energy_df.resample(\"1H\").interpolate(\"linear\")\n",
    "solar_energy_df = \\\n",
    "  (solar_energy_df - solar_energy_df.mean()) / solar_energy_df.std()\n",
    "\n",
    "training_ratio = 0.7\n",
    "\n",
    "training_limit = \\\n",
    "  solar_energy_df.index[\n",
    "      int(training_ratio*solar_energy_df.shape[0])\n",
    "    ]\n",
    "\n",
    "y_train_df = solar_energy_df.loc[:training_limit-pd.Timedelta(hours=1),\n",
    "                                  \"solar_mw\"]\n",
    "y_test_df = solar_energy_df.loc[training_limit:, \"solar_mw\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 14:22:44.858899: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-26 14:22:45.001135: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-26 14:22:45.001228: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-26 14:22:45.001245: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-26 14:22:45.056386: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from pydantic import NonNegativeInt, PositiveInt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "n_feats = 1\n",
    "input_memory=48\n",
    "\n",
    "def tensor_memory_reshaper(in_np:np.ndarray, out_np:Optional[np.ndarray],\n",
    "                           memory:NonNegativeInt,\n",
    "                           n_feats_internal:PositiveInt = n_feats):\n",
    "  in_np = in_np.reshape((-1,1,n_feats_internal))\n",
    "  for _ in range(memory):\n",
    "    next_np = in_np[1:,-1,:].reshape(((-1,1,n_feats_internal)))\n",
    "    in_np = np.concatenate((in_np[:-1,:,:], next_np), axis=1)\n",
    "\n",
    "  if out_np is not None:\n",
    "    return (tf.convert_to_tensor(in_np),\n",
    "            tf.convert_to_tensor(out_np[memory:]))\n",
    "  else:\n",
    "    return (tf.convert_to_tensor(in_np), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 14:22:48.805616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-26 14:22:48.955674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-26 14:22:48.956450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-26 14:22:48.960996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-26 14:22:48.961466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-26 14:22:48.961710: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-26 14:22:49.016094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-26 14:22:49.016519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-26 14:22:49.016616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-26 14:22:49.016682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2288 MB memory:  -> device: 0, name: NVIDIA RTX A500 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-11-26 14:22:51.835899: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-26 14:22:52.555904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8800\n",
      "2023-11-26 14:22:52.756547: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-26 14:22:53.052180: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563f8a6e0e80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-26 14:22:53.052249: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A500 Laptop GPU, Compute Capability 8.6\n",
      "2023-11-26 14:22:53.069842: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-26 14:22:53.190042: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: {'serial': 'model_20231126142249', 'input_memory': 72, 'head_size': 8, 'num_heads': 8, 'ff_dim': 10, 'mlp_units': 32, 'ST_RMSE': 0.9480818750876606, 'RMSE': 0.6528476601037452, 'MAE': 1.6593353325174087}\n",
      "Model: {'serial': 'model_20231126142408', 'input_memory': 48, 'head_size': 8, 'num_heads': 8, 'ff_dim': 10, 'mlp_units': 32, 'ST_RMSE': 0.7072564274340357, 'RMSE': 1.1301172225800964, 'MAE': 2.8481242969240377}\n",
      "Model: {'serial': 'model_20231126142512', 'input_memory': 24, 'head_size': 8, 'num_heads': 8, 'ff_dim': 10, 'mlp_units': 32, 'ST_RMSE': 0.3930467780593497, 'RMSE': 2485693051459.5938, 'MAE': 19854318895103.758}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import transformer_sv\n",
    "\n",
    "from keras.backend import clear_session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class StateResetCallback(keras.callbacks.Callback):\n",
    "  def on_epoch_begin(self, epoch, logs=None):\n",
    "    self.model.reset_states()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10,\n",
    "                                  restore_best_weights=True),\n",
    "    StateResetCallback()\n",
    "  ]\n",
    "\n",
    "model_dict = {}\n",
    "date_format = \"%Y%m%d%H%M%S\"\n",
    "\n",
    "try:\n",
    "  for input_memory in [72,48,24]:\n",
    "    x_train_np = np.pad(\n",
    "        y_train_df[:-1].to_numpy().reshape((-1,1)), ((input_memory+1,0),(0,0)), mode=\"edge\"\n",
    "      )\n",
    "    y_train_np = np.pad(y_train_df.to_numpy(), ((input_memory,0),), mode=\"edge\")\n",
    "\n",
    "    x_train_tensor,y_train_tensor = \\\n",
    "      tensor_memory_reshaper(x_train_np, y_train_np, input_memory)\n",
    "    for head_size in [8]:\n",
    "      for num_heads in [8]:\n",
    "        for ff_dim in [10]:\n",
    "          for mlp_units in [32]:\n",
    "            serial = \"model_\" + datetime.now().strftime(date_format)\n",
    "\n",
    "            clear_session()\n",
    "            \n",
    "            transformer_model = transformer_sv.build_model(\n",
    "                input_shape=x_train_tensor.shape[1:],\n",
    "                head_size=head_size,\n",
    "                num_heads=num_heads,\n",
    "                ff_dim=ff_dim,\n",
    "                num_transformer_blocks=1,\n",
    "                mlp_units=[mlp_units],\n",
    "                mlp_dropout=0.5,\n",
    "                dropout=0.5\n",
    "              )\n",
    "\n",
    "            transformer_model.compile(\n",
    "                loss=\"mse\",\n",
    "                optimizer=\"Adam\"\n",
    "              )\n",
    "\n",
    "            transformer_model.fit(\n",
    "                x=(x_train_tensor,x_train_tensor),\n",
    "                y=y_train_tensor,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                callbacks=callbacks,\n",
    "                verbose=0\n",
    "              )\n",
    "            transformer_model.save(f\"./models/{serial}.keras\")\n",
    "      \n",
    "            transformer_fit = transformer_model.predict(\n",
    "                x=(x_train_tensor,x_train_tensor),\n",
    "                verbose=0\n",
    "              ).flatten()\n",
    "\n",
    "            transformer_prediction = np.zeros(y_test_df.shape)\n",
    "            buffer = y_train_np[-(input_memory+1):].copy()\n",
    "            context,_ = tensor_memory_reshaper(buffer, None, input_memory, 1)\n",
    "            for idx in range(len(y_test_df)):\n",
    "              current_input,_ = tensor_memory_reshaper(buffer, None, input_memory, 1)\n",
    "              transformer_prediction[idx] = \\\n",
    "                transformer_model.predict((context,current_input),\n",
    "                                          verbose=0).flatten()[-1]\n",
    "\n",
    "              buffer[:-1] = buffer[1:]\n",
    "              buffer[-1] = transformer_prediction[idx]\n",
    "\n",
    "            st_rmse = np.sqrt(\n",
    "                np.mean(\n",
    "                    (transformer_prediction[:48]-y_test_df.to_numpy()[:48])**2\n",
    "                  )\n",
    "              )\n",
    "            transformer_rmse = np.sqrt(\n",
    "                np.mean((transformer_prediction-y_test_df.to_numpy())**2)\n",
    "              )\n",
    "            transformer_mae = np.abs(\n",
    "                transformer_prediction-y_test_df.to_numpy()\n",
    "              ).max()\n",
    "\n",
    "            model_dict[serial] = {\n",
    "              \"serial\": serial,\n",
    "              \"input_memory\": input_memory,\n",
    "              \"head_size\": head_size,\n",
    "              \"num_heads\": num_heads,\n",
    "              \"ff_dim\": ff_dim,\n",
    "              \"mlp_units\": mlp_units,\n",
    "              \"ST_RMSE\": st_rmse,\n",
    "              \"RMSE\": transformer_rmse,\n",
    "              \"MAE\": transformer_mae\n",
    "            }\n",
    "            print(f\"Model: {model_dict[serial]}\")\n",
    "\n",
    "            plt.figure(figsize=(8,5))\n",
    "            plt.plot(solar_energy_df[\"solar_mw\"],\n",
    "                    label=\"Measured\")\n",
    "            plt.plot(y_train_df.index, transformer_fit, label=\"Fitted\")\n",
    "            plt.plot(y_test_df.index, transformer_prediction, label=\"Estimated\")\n",
    "            plt.autoscale(True, \"x\", tight=True)\n",
    "            plt.title(f\"Classic Transformer - {serial}\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"./report/figures/{serial}_fit.svg\")\n",
    "            plt.close(\"all\")\n",
    "finally:\n",
    "  model_df = pd.DataFrame.from_dict(list(model_dict.values()))\n",
    "  model_df.to_excel(f\"./results_{datetime.now().strftime(date_format)}.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADAML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
